{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubairlalani/CS598DLHFinalProject/blob/main/DLHFinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First add USER and TOKEN under \"Secrets\" tab on the left of Colab. We download all the entire repo so that we can reuse files provided by the MIMIC-Extract and CFVAE repositories."
      ],
      "metadata": {
        "id": "n7xCf--bZ5Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "USER = userdata.get('USER')\n",
        "TOKEN = userdata.get('TOKEN')\n",
        "!git clone https://{USER}:{TOKEN}@github.com/zubairlalani/CS598DLHFinalProject.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "aBr-5SSPZZGd",
        "outputId": "3d7a1d73-db72-4703-8d78-258a9abd0047"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret USER does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d0d2a4772397>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mUSER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'USER'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://{USER}:{TOKEN}@github.com/zubairlalani/CS598DLHFinalProject.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret USER does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will enter our project directory"
      ],
      "metadata": {
        "id": "NAqicHBgLu0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CS598DLHFinalProject/"
      ],
      "metadata": {
        "id": "XoaOleMcY2cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run CFVAE Using MNIST Data"
      ],
      "metadata": {
        "id": "a4_yDU_HLYYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "import struct\n",
        "from array import array\n",
        "from os.path import join\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "DCURR5DVVgeJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the MNIST data loader (only needed subset of 3 and 8)\n",
        "class MnistDataloader:\n",
        "    def __init__(self, training_images_filepath, training_labels_filepath,\n",
        "                 test_images_filepath, test_labels_filepath):\n",
        "        self.training_images_filepath = training_images_filepath\n",
        "        self.training_labels_filepath = training_labels_filepath\n",
        "        self.test_images_filepath = test_images_filepath\n",
        "        self.test_labels_filepath = test_labels_filepath\n",
        "\n",
        "    def read_images_labels(self, images_filepath, labels_filepath):\n",
        "        with open(labels_filepath, 'rb') as file:\n",
        "            magic, size = struct.unpack(\">II\", file.read(8))\n",
        "            labels = array(\"B\", file.read())\n",
        "\n",
        "        with open(images_filepath, 'rb') as file:\n",
        "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
        "            image_data = array(\"B\", file.read())\n",
        "        images = []\n",
        "        for i in range(size):\n",
        "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols]).reshape(28, 28)\n",
        "            images.append(img)\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def load_data(self):\n",
        "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
        "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
        "        return (x_train, y_train), (x_test, y_test)\n"
      ],
      "metadata": {
        "id": "6GglGjs-V_1e"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download MNIST data"
      ],
      "metadata": {
        "id": "7b2cpndDYu-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz"
      ],
      "metadata": {
        "id": "HJVZ_l77YaEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95df810-70f4-4069-b4c3-379509c790f8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-27 22:44:47--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2025-04-27 22:44:47--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.1’\n",
            "\n",
            "MNIST.tar.gz.1          [      <=>           ]  33.20M  3.52MB/s    in 19s     \n",
            "\n",
            "2025-04-27 22:45:07 (1.72 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder paths (adjust to actual file locations)\n",
        "input_path = \"MNIST/raw/\"\n",
        "training_images_filepath = join(input_path, 'train-images-idx3-ubyte')\n",
        "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte')\n",
        "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte')\n",
        "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte')"
      ],
      "metadata": {
        "id": "uvXXpDypWCfq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "mnist_loader = MnistDataloader(training_images_filepath, training_labels_filepath,\n",
        "                                test_images_filepath, test_labels_filepath)\n",
        "(x_train, y_train), (x_test, y_test) = mnist_loader.load_data()"
      ],
      "metadata": {
        "id": "hrSiX2kLWGnA"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Filter only digits 3 and 8\n",
        "def filter_digits(images, labels, digit1=3, digit2=8) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    mask = (labels == digit1) | (labels == digit2)\n",
        "    filtered_images = images[mask]\n",
        "    filtered_labels = labels[mask]\n",
        "    binary_labels = (filtered_labels == digit2).astype(int)  # Label '8' as 1, '3' as 0\n",
        "    return filtered_images, binary_labels\n",
        "\n",
        "x_train, y_train = filter_digits(x_train, y_train)\n",
        "x_test, y_test = filter_digits(x_test, y_test)"
      ],
      "metadata": {
        "id": "rObI_B72WQiU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and reshape data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)"
      ],
      "metadata": {
        "id": "gBwbQbFmWSqk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train into train and val\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "o5h2wrlPWUFw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors\n",
        "train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "val_dataset = TensorDataset(torch.tensor(x_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "test_dataset = TensorDataset(torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
        "\n",
        "# Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "wyNGNhoAWW1U"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display few samples\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    axs[i].imshow(x_train[i].reshape(28, 28), cmap=\"gray\")\n",
        "    axs[i].set_title(f\"Label: {y_train[i]}\")\n",
        "    axs[i].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "9f5luuKLWZzT",
        "outputId": "34a349f6-fb83-4a7d-8f94-a26a09a390d9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple MLP\n",
        "class MNISTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2)  # Output logits for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "InKZ40-TWecl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MNISTBinaryClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "SRwNKzVRWfl4"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation accuracy\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).argmax(dim=1).cpu()\n",
        "            all_preds.extend(preds)\n",
        "            all_targets.extend(yb)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    print(f\"Epoch {epoch+1}: Validation Accuracy = {acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_t9W7h1WjPn",
        "outputId": "c8a0f519-ae4e-4864-b489-a3448986ec55"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation Accuracy = 96.44%\n",
            "Epoch 2: Validation Accuracy = 98.11%\n",
            "Epoch 3: Validation Accuracy = 98.33%\n",
            "Epoch 4: Validation Accuracy = 98.67%\n",
            "Epoch 5: Validation Accuracy = 98.83%\n",
            "Epoch 6: Validation Accuracy = 99.11%\n",
            "Epoch 7: Validation Accuracy = 99.00%\n",
            "Epoch 8: Validation Accuracy = 99.17%\n",
            "Epoch 9: Validation Accuracy = 98.67%\n",
            "Epoch 10: Validation Accuracy = 99.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set evaluation\n",
        "model.eval()\n",
        "all_preds, all_targets = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        preds = model(xb).argmax(dim=1).cpu()\n",
        "        all_preds.extend(preds)\n",
        "        all_targets.extend(yb)\n",
        "test_acc = accuracy_score(all_targets, all_preds)\n",
        "print(f\"\\n✅ Test Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svdYncGcWmXT",
        "outputId": "a939d903-d645-491b-e8d0-0f5393690880"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Test Accuracy: 99.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), \"mnist_3vs8_classifier.pt\")"
      ],
      "metadata": {
        "id": "Ti_q-xf0WpC0"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CFVAE from your model.py\n",
        "class CFVAE(nn.Module):\n",
        "    def __init__(self, feat_dim, emb_dim1, _mlp_dim1, _mlp_dim2, _mlp_dim3, mlp_inpemb, f_dim1, f_dim2):\n",
        "        super(CFVAE, self).__init__()\n",
        "        self.enc1 = nn.Linear(feat_dim, emb_dim1)\n",
        "        self.enc2 = nn.Linear(emb_dim1, 64)\n",
        "        self.dec1 = nn.Linear(32, emb_dim1)\n",
        "        self.dec2 = nn.Linear(emb_dim1, feat_dim)\n",
        "        self.word_embeddings = nn.Linear(feat_dim, mlp_inpemb)\n",
        "        self.ln1 = nn.LayerNorm(mlp_inpemb)\n",
        "        self.fc1 = nn.Linear(mlp_inpemb, f_dim1)\n",
        "        self.ln2 = nn.LayerNorm(f_dim1)\n",
        "        self.fc2 = nn.Linear(f_dim1, f_dim2)\n",
        "        self.scorelayer = nn.Linear(f_dim2, 1)\n",
        "        self.pred = nn.Linear(1, 2)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc = torch.relu(self.enc1(x))\n",
        "        enc = self.enc2(enc).view(-1, 2, 32)\n",
        "        mu, log_var = enc[:, 0, :], enc[:, 1, :]\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        dec = torch.relu(self.dec1(z))\n",
        "        recon = self.dec2(dec)\n",
        "        embed = self.word_embeddings(recon)\n",
        "        embed = self.ln1(embed)\n",
        "        out = torch.relu(self.fc1(embed))\n",
        "        out = self.ln2(out)\n",
        "        out = torch.relu(self.fc2(out))\n",
        "        out = self.scorelayer(out)\n",
        "        pred = self.pred(out)\n",
        "        return recon, mu, log_var, pred\n",
        "\n",
        "# Final loss function for VAE\n",
        "def final_loss(bce_loss, mu, logvar):\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return bce_loss + KLD\n"
      ],
      "metadata": {
        "id": "Ws49vpmvWpve"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config --global user.email \"zubairlalani07@gmail.com\"\n",
        "# !git config --global user.name \"zubairlalani\"\n",
        "# !git add CS598DLHFinalProject.ipynb\n",
        "# !git commit -m \"Convert code to Google Colab Notebook\"\n",
        "# !git push origin main  # or whatever your branch is"
      ],
      "metadata": {
        "id": "Qu-QvMv8bdwa"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add CFVAE subfolder to the Python path"
      ],
      "metadata": {
        "id": "u1lSp8DLg21C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/CS598DLHFinalProject/CFVAE')"
      ],
      "metadata": {
        "id": "i5jCmqT-gSmb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import CFVAE\n",
        "from utils import final_loss  # or train_vae, evaluate_vae, etc."
      ],
      "metadata": {
        "id": "nOdIqGKVg6Zg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f58e9be7-d41c-4a97-856a-1b9d0796b7e5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-1bdd1459513b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCFVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfinal_loss\u001b[0m  \u001b[0;31m# or train_vae, evaluate_vae, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CFVAE(\n",
        "    feat_dim=784,\n",
        "    emb_dim1=64,\n",
        "    _mlp_dim1=0, _mlp_dim2=0, _mlp_dim3=0,\n",
        "    mlp_inpemb=64,\n",
        "    f_dim1=32,\n",
        "    f_dim2=16\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "atbGrhMVhQE-"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MNISTBinaryClassifier().to(device)\n",
        "classifier.load_state_dict(torch.load(\"mnist_3vs8_classifier.pt\"))\n",
        "classifier.eval()\n",
        "for param in classifier.parameters():\n",
        "    param.requires_grad = False  # Freeze classifier"
      ],
      "metadata": {
        "id": "1OEd9zI2lHgp"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: counterfactuals don't seem to be correct - need to look into the codebase more"
      ],
      "metadata": {
        "id": "F1AiPucGhWZu"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare only '8' examples to flip into '3'\n",
        "X = torch.tensor(x_train[y_train == 1], dtype=torch.float32)\n",
        "Y = torch.tensor(y_train[y_train == 1], dtype=torch.long)  # All 1s (8)\n",
        "\n",
        "# Setup\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion_recon = nn.MSELoss()\n",
        "criterion_cf = nn.CrossEntropyLoss()\n",
        "batch_size, epochs = 50, 32\n",
        "\n",
        "# Train CFVAE\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    perm = torch.randperm(X.size(0))\n",
        "    for i in range(0, X.size(0), batch_size):\n",
        "        idx = perm[i:i+batch_size]\n",
        "        x_batch = X[idx].to(device)\n",
        "        y_cf = torch.zeros(x_batch.size(0), dtype=torch.long).to(device)  # Target class: '3' == 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon, mu, logvar, _ = model(x_batch)\n",
        "\n",
        "        # Standard VAE loss\n",
        "        recon_loss = criterion_recon(recon, x_batch)\n",
        "        kld = final_loss(recon_loss, mu, logvar)\n",
        "\n",
        "        # Use classifier to compute CF loss (based on its prediction of the *reconstruction*)\n",
        "        clf_pred = classifier(recon)\n",
        "        cf_loss = criterion_cf(clf_pred, y_cf)\n",
        "\n",
        "        # Total loss\n",
        "        loss = kld + 100 * cf_loss  # Scale CF loss higher for stronger push\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Recon Loss={recon_loss.item():.4f}, CF Loss={cf_loss.item():.4f}, Total Loss={loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd8jRHGWlryI",
        "outputId": "45facdfe-3d13-4aa9-9bca-ccb7e6292e93"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Recon Loss=0.2060, CF Loss=0.0000, Total Loss=0.2832\n",
            "Epoch 2: Recon Loss=0.1974, CF Loss=0.0000, Total Loss=0.2436\n",
            "Epoch 3: Recon Loss=0.1766, CF Loss=0.0000, Total Loss=0.1998\n",
            "Epoch 4: Recon Loss=0.1730, CF Loss=0.0000, Total Loss=0.1877\n",
            "Epoch 5: Recon Loss=0.1575, CF Loss=0.0000, Total Loss=0.1659\n",
            "Epoch 6: Recon Loss=0.1492, CF Loss=0.0000, Total Loss=0.1539\n",
            "Epoch 7: Recon Loss=0.1434, CF Loss=0.0000, Total Loss=0.1468\n",
            "Epoch 8: Recon Loss=0.1397, CF Loss=0.0000, Total Loss=0.1421\n",
            "Epoch 9: Recon Loss=0.1422, CF Loss=0.0000, Total Loss=0.1437\n",
            "Epoch 10: Recon Loss=0.1337, CF Loss=0.0000, Total Loss=0.1349\n",
            "Epoch 11: Recon Loss=0.1240, CF Loss=0.0000, Total Loss=0.1251\n",
            "Epoch 12: Recon Loss=0.1276, CF Loss=0.0000, Total Loss=0.1290\n",
            "Epoch 13: Recon Loss=0.1171, CF Loss=0.0000, Total Loss=0.1179\n",
            "Epoch 14: Recon Loss=0.1112, CF Loss=0.0000, Total Loss=0.1119\n",
            "Epoch 15: Recon Loss=0.1172, CF Loss=0.0000, Total Loss=0.1178\n",
            "Epoch 16: Recon Loss=0.1098, CF Loss=0.0000, Total Loss=0.1103\n",
            "Epoch 17: Recon Loss=0.1054, CF Loss=0.0000, Total Loss=0.1061\n",
            "Epoch 18: Recon Loss=0.0981, CF Loss=0.0000, Total Loss=0.0984\n",
            "Epoch 19: Recon Loss=0.1036, CF Loss=0.0000, Total Loss=0.1040\n",
            "Epoch 20: Recon Loss=0.0989, CF Loss=0.0000, Total Loss=0.0992\n",
            "Epoch 21: Recon Loss=0.1000, CF Loss=0.0000, Total Loss=0.1002\n",
            "Epoch 22: Recon Loss=0.0931, CF Loss=0.0000, Total Loss=0.0936\n",
            "Epoch 23: Recon Loss=0.0893, CF Loss=0.0000, Total Loss=0.0908\n",
            "Epoch 24: Recon Loss=0.0883, CF Loss=0.0000, Total Loss=0.0886\n",
            "Epoch 25: Recon Loss=0.0855, CF Loss=0.0000, Total Loss=0.0858\n",
            "Epoch 26: Recon Loss=0.0939, CF Loss=0.0000, Total Loss=0.0941\n",
            "Epoch 27: Recon Loss=0.0881, CF Loss=0.0000, Total Loss=0.0886\n",
            "Epoch 28: Recon Loss=0.0806, CF Loss=0.0000, Total Loss=0.0812\n",
            "Epoch 29: Recon Loss=0.0734, CF Loss=0.0000, Total Loss=0.0738\n",
            "Epoch 30: Recon Loss=0.0771, CF Loss=0.0000, Total Loss=0.0779\n",
            "Epoch 31: Recon Loss=0.0785, CF Loss=0.0000, Total Loss=0.0788\n",
            "Epoch 32: Recon Loss=0.0788, CF Loss=0.0000, Total Loss=0.0794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CFVAE\n",
        "# X = torch.tensor(x_train[y_train == 1], dtype=torch.float32)\n",
        "# Y = torch.tensor(y_train[y_train == 1], dtype=torch.long)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = CFVAE(784, 64, 0, 0, 0, 64, 32, 16).to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# criterion_recon = nn.MSELoss()\n",
        "# criterion_cf = nn.CrossEntropyLoss()\n",
        "# batch_size, epochs = 32, 50\n",
        "\n",
        "# model.train()\n",
        "# for epoch in range(epochs):\n",
        "#     perm = torch.randperm(X.size(0))\n",
        "#     for i in range(0, X.size(0), batch_size):\n",
        "#         idx = perm[i:i+batch_size]\n",
        "#         x_batch, y_batch = X[idx].to(device), Y[idx].to(device)\n",
        "#         y_cf = 1 - y_batch\n",
        "#         optimizer.zero_grad()\n",
        "#         recon, mu, logvar, pred = model(x_batch)\n",
        "#         recon_loss = criterion_recon(recon, x_batch)\n",
        "#         kld = final_loss(recon_loss, mu, logvar)\n",
        "#         cf_loss = criterion_cf(pred, y_cf)\n",
        "#         loss = kld + 50 * cf_loss\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#     print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "# # Visualize\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     sample = X[:5].to(device)\n",
        "#     recon, _, _, _ = model(sample)\n",
        "\n",
        "# fig, axs = plt.subplots(2, 5, figsize=(12, 5))\n",
        "# for i in range(5):\n",
        "#     axs[0, i].imshow(sample[i].cpu().numpy().reshape(28, 28), cmap=\"gray\")\n",
        "#     axs[0, i].set_title(\"Original 8\")\n",
        "#     axs[0, i].axis(\"off\")\n",
        "#     axs[1, i].imshow(recon[i].cpu().numpy().reshape(28, 28), cmap=\"gray\")\n",
        "#     axs[1, i].set_title(\"Counterfactual → 3\")\n",
        "#     axs[1, i].axis(\"off\")\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample = X[:5].to(device)\n",
        "    recon, _, _, _ = model(sample)\n",
        "\n",
        "fig, axs = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i in range(5):\n",
        "    axs[0, i].imshow(sample[i].cpu().numpy().reshape(28, 28), cmap=\"gray\")\n",
        "    axs[0, i].set_title(\"Original 8\")\n",
        "    axs[0, i].axis(\"off\")\n",
        "    axs[1, i].imshow(recon[i].cpu().numpy().reshape(28, 28), cmap=\"gray\")\n",
        "    axs[1, i].set_title(\"Counterfactual → 3\")\n",
        "    axs[1, i].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: Classifier check\n",
        "with torch.no_grad():\n",
        "    preds = classifier(recon).argmax(dim=1)\n",
        "    print(\"Classifier predictions of counterfactuals:\", preds.cpu().numpy())  # Expect all 0s (3s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "VRN4vZjGiZtW",
        "outputId": "77e61b5a-773c-4431-d945-fdbc1a98764c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier predictions of counterfactuals: [0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MTnTcIb3ozR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILIZING MIMIC-EXTRACT OUTPUT\n",
        "\n",
        "## Importing the data"
      ],
      "metadata": {
        "id": "rv36fBTF3pSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zBFvbKfpMKdM",
        "outputId": "d3ac57e8-f219-46a8-c9d6-3b8a987ab28a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only need to run the below if you are not already in the CS598DLHFinalProject directory."
      ],
      "metadata": {
        "id": "a9kWKe4eL_v8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CS598DLHFinalProject/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tav1Qq5jrmTk",
        "outputId": "432da969-0cb6-4ffa-86c5-a3763ce93ed3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'CS598DLHFinalProject/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import scipy.stats as ss"
      ],
      "metadata": {
        "id": "gIQkCtiiibIb"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from simple_impute import simple_imputer"
      ],
      "metadata": {
        "id": "4rMLjqhijCXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "5a772080-a783-4804-dc57-325b6d948311"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'simple_impute'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-51d98e0c1204>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimple_impute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_imputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simple_impute'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper uses a slice_size of 48 and prediction_window 24. Basically, 48 hours of temporal patient data is the \"context\" from which the model will try to predict if the patient needs a vasopressor (which is considered an \"intervention\"). In our case, however, since we are using the demo data, we don't have enough data to do a train,val,test split and have those same sizes, so we cut the window sizes in half."
      ],
      "metadata": {
        "id": "Th_BV98L30yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INTERVENTION = 'vaso'\n",
        "RANDOM = 0\n",
        "MAX_LEN = 240\n",
        "SLICE_SIZE = 24\n",
        "GAP_TIME = 0\n",
        "PREDICTION_WINDOW = 12\n",
        "OUTCOME_TYPE = 'binary'\n",
        "NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "Zbnxh-dvjeme"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper uses the interventions for the output label (just a binary 0 or 1 in a column called \"vaso\"). The input features used are spread out over a couple of files, namely \"vitals_labs\" and \"patients\". The vitals_labs contains most of the time-series data. Age and gender is used from the patients data (this data is static since it doesn't change as time goes on unlike the vitals)"
      ],
      "metadata": {
        "id": "UFL7qs7o4Ms4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAFILE = 'extract/all_hourly_data.h5'"
      ],
      "metadata": {
        "id": "tKX9SGNXkEWs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_hdf(DATAFILE,'vitals_labs')\n",
        "Y = pd.read_hdf(DATAFILE,'interventions')\n",
        "static = pd.read_hdf(DATAFILE,'patients')"
      ],
      "metadata": {
        "id": "tb0xnIRikjrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4b0adbac-6dc6-46cd-e728-7981e6af10d8"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File extract/all_hourly_data.h5 does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-846b2bd99601>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAFILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vitals_labs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAFILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'interventions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstatic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAFILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'patients'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File extract/all_hourly_data.h5 does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y[[INTERVENTION]]"
      ],
      "metadata": {
        "id": "dgKrgAGCkqLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "1f717d73-8f27-45c0-c54f-53b112436b48"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "new(): invalid data type 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-7c678866f020>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINTERVENTION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mSulFAPV4msO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Shape of X : ', X.shape)\n",
        "print ('Shape of Y : ', Y.shape)\n",
        "print ('Shape of static : ', static.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "4cbv-lqRlfh_",
        "outputId": "3d35ea77-a590-4364-b714-fd59a125fc7f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X :  torch.Size([4982, 784])\n",
            "Shape of Y :  torch.Size([4982])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'static' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-f3926b271bc9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of X : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of Y : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of static : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'static' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training, validation, test split"
      ],
      "metadata": {
        "id": "z3Hmm7wFNk-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the train,val,test split using the 70%, 15%, 15% split as specified in the paper. Stratify across mortality rate to keep it balanced across the split."
      ],
      "metadata": {
        "id": "5o_grnf54qRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids, test_ids = train_test_split(static.reset_index(), test_size=0.3,\n",
        "                                       random_state=RANDOM, stratify=static['mort_hosp'])\n",
        "split_train_ids, val_ids = train_test_split(train_ids, test_size=0.15,\n",
        "                                            random_state=RANDOM, stratify=train_ids['mort_hosp'])"
      ],
      "metadata": {
        "id": "PSXPXIPLl8yE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "114d56f3-4e97-4aae-d463-6bc07b090d2d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'static' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-e9dc285bb600>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ids, test_ids = train_test_split(static.reset_index(), test_size=0.3,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                        random_state=RANDOM, stratify=static['mort_hosp'])\n\u001b[1;32m      3\u001b[0m split_train_ids, val_ids = train_test_split(train_ids, test_size=0.15,\n\u001b[1;32m      4\u001b[0m                                             random_state=RANDOM, stratify=train_ids['mort_hosp'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'static' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The imputer cleans the data (it is a file provided by the MIMIC_Extract repo in simple_impute.py). We have copied the file over into our repo."
      ],
      "metadata": {
        "id": "Ctc3dDqW45nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean = simple_imputer(X.copy(),train_ids['subject_id'])"
      ],
      "metadata": {
        "id": "lcdhI_UMl_kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning"
      ],
      "metadata": {
        "id": "R258RE7l5KtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax(x):# normalize\n",
        "    mins = x.min()\n",
        "    maxes = x.max()\n",
        "    x_std = (x - mins) / (maxes - mins)\n",
        "    return x_std"
      ],
      "metadata": {
        "id": "paXpKJaWlgtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def std_time_since_measurement(x):\n",
        "    idx = pd.IndexSlice\n",
        "    x = np.where(x==100, 0, x)\n",
        "    means = x.mean()\n",
        "    stds = x.std()\n",
        "    x_std = (x - means)/stds\n",
        "    return x_std"
      ],
      "metadata": {
        "id": "nVF6ZvsplwXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = pd.IndexSlice\n",
        "X_std = X_clean.copy()\n",
        "X_std.loc[:,idx[:,'mean']] = X_std.loc[:,idx[:,'mean']].apply(lambda x: minmax(x))\n",
        "X_std.loc[:,idx[:,'time_since_measured']] = X_std.loc[:,idx[:,'time_since_measured']].apply(lambda x: std_time_since_measurement(x))"
      ],
      "metadata": {
        "id": "zRVrgW_NlyPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std.columns = X_std.columns.droplevel(-1)"
      ],
      "metadata": {
        "id": "qXTIsqVXmHZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std.columns.duplicated().any()"
      ],
      "metadata": {
        "id": "LqzWbBUmlz08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std.columns"
      ],
      "metadata": {
        "id": "egSc6kpgolki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has columns with the same name. For example, there are 3 different columns called \"heart rate\". Based on looking at the CFVAE repo, it seems like they renamed the duplicate columns so that it is \"heart rate\", \"heart rate.1\", \"heart rate.2\", etc. We'll do the same so that we easily port over their code."
      ],
      "metadata": {
        "id": "fs64pO9i5PZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = pd.Series(X_std.columns)\n",
        "\n",
        "for dup in X_std.columns[X_std.columns.duplicated(keep=False)]:\n",
        "    dup_indices = np.where(X_std.columns == dup)[0]  # Find ALL locations\n",
        "    for idx, d_idx in enumerate(dup_indices):\n",
        "        if idx == 0:\n",
        "            # First occurrence: keep the original name\n",
        "            cols[d_idx] = dup\n",
        "        else:\n",
        "            # Later duplicates: add .1, .2, etc.\n",
        "            cols[d_idx] = f\"{dup}.{idx}\"\n",
        "\n",
        "X_std.columns=cols"
      ],
      "metadata": {
        "id": "49FWP7UomPN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std.columns"
      ],
      "metadata": {
        "id": "7vKkS6qDoRNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "static"
      ],
      "metadata": {
        "id": "hMRcvhrWobTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper categorizes the age into 4 groups \"age_1\" \"age_2\" \"age_3\" \"age_4\"."
      ],
      "metadata": {
        "id": "WFQlWogZ5rQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_age(age):\n",
        "    if age > 10 and age <= 30:\n",
        "        cat = int(1)\n",
        "    elif age > 30 and age <= 50:\n",
        "        cat = int(2)\n",
        "    elif age > 50 and age <= 70:\n",
        "        cat = int(3)\n",
        "    else:\n",
        "        cat = int(4)\n",
        "    return cat"
      ],
      "metadata": {
        "id": "10ptcGtDqRmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use gender, first_careunit, age and ethnicity for prediction\n",
        "static_to_keep = static[['gender', 'age']]\n",
        "static_to_keep.loc[:, 'age'] = static_to_keep['age'].apply(categorize_age).astype(int)\n",
        "static_to_keep[\"age\"] = static_to_keep[\"age\"].astype(int)\n",
        "static_to_keep = pd.get_dummies(static_to_keep, columns = ['gender', 'age'])"
      ],
      "metadata": {
        "id": "vQ_L6mHHqZqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "static_to_keep"
      ],
      "metadata": {
        "id": "PGS-54srr_yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "q3tBBd9fN6Jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter the features to only use the list of vitals features used in CFVAE"
      ],
      "metadata": {
        "id": "vkg8ADkf6DY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vital_list = ['heart rate', 'heart rate.1', 'systolic blood pressure', 'systolic blood pressure.1',\n",
        "              'diastolic blood pressure', 'diastolic blood pressure.1', 'oxygen saturation', 'oxygen saturation.1',\n",
        "              'respiratory rate', 'respiratory rate.1', 'glascow coma scale total', 'glascow coma scale total.1',\n",
        "              'temperature', 'temperature.1']\n",
        "X_std_filtered = X_std.loc[:, vital_list]"
      ],
      "metadata": {
        "id": "SuCoNgKytMeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_std_filtered"
      ],
      "metadata": {
        "id": "r22vBjZ4t9-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the vitals features with the static features (gender and age)."
      ],
      "metadata": {
        "id": "75k-i1Dd6Pk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge time series and static data\n",
        "X_merge = pd.merge(X_std_filtered.reset_index(), static_to_keep.reset_index(), on=['subject_id','icustay_id','hadm_id'])\n",
        "# add absolute time feature\n",
        "# abs_time = X_merge['intime'] + pd.to_timedelta(X_merge['hours_in'], unit='h')\n",
        "X_merge = X_merge.set_index(['subject_id','icustay_id','hadm_id','hours_in'])"
      ],
      "metadata": {
        "id": "vO0EDc8zuALG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_std, X_clean, X_std_filtered"
      ],
      "metadata": {
        "id": "Yg4b50QGuzeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will be working with matrices not pandas dataframe, so here we create the matrices."
      ],
      "metadata": {
        "id": "PEownV5OOU18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_x_matrix(x):\n",
        "    zeros = np.zeros((MAX_LEN, x.shape[1]-4))\n",
        "    x = x.values\n",
        "    x = x[:(MAX_LEN), 4:]\n",
        "    zeros[0:x.shape[0], :] = x\n",
        "    return zeros\n",
        "\n",
        "def create_y_matrix(y):\n",
        "    zeros = np.zeros((MAX_LEN, y.shape[1]-4))\n",
        "    y = y.values\n",
        "    y = y[:,4:]\n",
        "    y = y[:MAX_LEN, :]\n",
        "    zeros[:y.shape[0], :] = y\n",
        "    return zeros"
      ],
      "metadata": {
        "id": "J3MEDM6YvYqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(list(X_merge.reset_index().groupby('subject_id').apply(create_x_matrix)))\n",
        "y = np.array(list(Y.reset_index().groupby('subject_id').apply(create_y_matrix)))[:,:,0]"
      ],
      "metadata": {
        "id": "4eIkPKKtvcEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = np.array(list(X_merge.reset_index().groupby('subject_id').apply(lambda x: x.shape[0])))"
      ],
      "metadata": {
        "id": "uJMKdBDRvfVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = pd.Series(X_merge.reset_index()['subject_id'].unique())"
      ],
      "metadata": {
        "id": "H59pixZzvh-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X tensor shape: \", x.shape)\n",
        "print(\"Y tensor shape: \", y.shape)\n",
        "print(\"lengths shape: \", lengths.shape)"
      ],
      "metadata": {
        "id": "zUeDomC_vjqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = np.where(keys.isin(train_ids['subject_id']))[0]\n",
        "test_indices = np.where(keys.isin(test_ids['subject_id']))[0]\n",
        "train_static = train_ids\n",
        "split_train_indices = np.where(keys.isin(split_train_ids['subject_id']))[0]\n",
        "val_indices = np.where(keys.isin(val_ids['subject_id']))[0]"
      ],
      "metadata": {
        "id": "XP80Mg7zvkz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = x[split_train_indices]\n",
        "Y_train = y[split_train_indices]\n",
        "X_test = x[test_indices]\n",
        "Y_test = y[test_indices]\n",
        "X_val = x[val_indices]\n",
        "Y_val = y[val_indices]\n",
        "lengths_train = lengths[split_train_indices]\n",
        "lengths_val = lengths[val_indices]\n",
        "lengths_test = lengths[test_indices]"
      ],
      "metadata": {
        "id": "-CVh0aVrvnOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training size: \", X_train.shape[0])\n",
        "print(\"Validation size: \", X_val.shape[0])\n",
        "print(\"Test size: \", X_test.shape[0])"
      ],
      "metadata": {
        "id": "ejanj1F0volm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAINING:\")\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "print(\"VALIDATION:\")\n",
        "print(X_val.shape)\n",
        "print(Y_val.shape)\n",
        "\n",
        "print(\"TESTING:\")\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "metadata": {
        "id": "Bk_z5puFvpx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See Appeendix C of the paper. This segments the data into windows and creates the \"intv24\" (in this case it's really intv12 since we are using a prediction window of 12) for the output label."
      ],
      "metadata": {
        "id": "nlclwckf6dQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_3d_tensor_slices(X_tensor, Y_tensor, lengths):\n",
        "\n",
        "    num_patients = X_tensor.shape[0]\n",
        "    timesteps = X_tensor.shape[1]\n",
        "    num_features = X_tensor.shape[2]\n",
        "    X_tensor_new = np.zeros((lengths.sum(), SLICE_SIZE, num_features + 1))\n",
        "    Y_tensor_new = np.zeros((lengths.sum(), 2))\n",
        "    current_row = 0\n",
        "    for patient_index in range(num_patients):\n",
        "        x_patient = X_tensor[patient_index]\n",
        "        y_patient = Y_tensor[patient_index]\n",
        "        length = lengths[patient_index]\n",
        "\n",
        "        for timestep in range(length - PREDICTION_WINDOW - GAP_TIME - SLICE_SIZE):\n",
        "            x_window = x_patient[timestep:timestep+SLICE_SIZE]\n",
        "            y_window = y_patient[timestep:timestep+SLICE_SIZE]\n",
        "            x_window = np.concatenate((x_window, np.expand_dims(y_window,1)), axis=1)\n",
        "            result_window = y_patient[timestep+SLICE_SIZE+GAP_TIME:timestep+SLICE_SIZE+GAP_TIME+PREDICTION_WINDOW]\n",
        "            result_window_diff = set(np.diff(result_window))\n",
        "            future_window = y_patient[timestep+SLICE_SIZE+GAP_TIME:]\n",
        "            #if 1 in result_window_diff: pdb.set_trace()\n",
        "            # gap_window = y_patient[timestep+SLICE_SIZE:timestep+SLICE_SIZE+GAP_TIME]\n",
        "            # gap_window_diff = set(np.diff(gap_window))\n",
        "\n",
        "            if 1 in future_window:\n",
        "              tintv = np.argmax(future_window == 1)\n",
        "            else:\n",
        "              tintv = 1000\n",
        "\n",
        "            if OUTCOME_TYPE == 'binary':\n",
        "                if max(result_window) == 1:\n",
        "                    result = 1\n",
        "                elif max(result_window) == 0:\n",
        "                    result = 0\n",
        "                if result != None:\n",
        "                    X_tensor_new[current_row] = x_window\n",
        "                    Y_tensor_new[current_row] = (result, tintv)\n",
        "                    current_row += 1\n",
        "\n",
        "    X_tensor_new = X_tensor_new[:current_row,:,:]\n",
        "    Y_tensor_new = Y_tensor_new[:current_row, :]\n",
        "    return X_tensor_new, Y_tensor_new"
      ],
      "metadata": {
        "id": "_35p1HuxvrDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = make_3d_tensor_slices(X_train, Y_train, lengths_train)\n",
        "x_val, y_val = make_3d_tensor_slices(X_val, Y_val, lengths_val)\n",
        "x_test, y_test = make_3d_tensor_slices(X_test, Y_test, lengths_test)"
      ],
      "metadata": {
        "id": "WUvBvOkbvtFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_classes = label_binarize(y_train, classes=range(NUM_CLASSES))\n",
        "# y_val_classes = label_binarize(y_val, classes=range(NUM_CLASSES))\n",
        "# y_test_classes = label_binarize(y_test, classes=range(NUM_CLASSES))"
      ],
      "metadata": {
        "id": "CDi0YgQuvubW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train, Y_train, X_test, Y_test, X_val, Y_val"
      ],
      "metadata": {
        "id": "vB8x_rB8xFyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('shape of x_train: ', x_train.shape)\n",
        "print('shape of x_val: ', x_val.shape)\n",
        "print('shape of x_test: ', x_test.shape)"
      ],
      "metadata": {
        "id": "nbvmsnABysnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We contenate all the features for a window into a single row. Since the static features (age and gender) doesn't change over time for a patient, that means that when we concatenate the features for a window of a specific patient into a row, we effectively remove a lot of data that was being repeated across rows."
      ],
      "metadata": {
        "id": "Irebn6VZOrJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "static_col = static_to_keep.shape[1] - 1\n",
        "time_series_col = X_merge.shape[1] - static_col"
      ],
      "metadata": {
        "id": "bSoOWCpTyt4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicate_static(x):\n",
        "    x_static = x[:,0,time_series_col:x.shape[2]-1]\n",
        "    x_timeseries = np.reshape(x[:,:,:time_series_col],(x.shape[0], -1))\n",
        "    x_int = x[:,:,-1]\n",
        "    x_concat = np.concatenate((x_static, x_timeseries, x_int), axis=1)\n",
        "    return x_concat"
      ],
      "metadata": {
        "id": "QFzpyj6ryyss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate hourly features\n",
        "x_train_concat = remove_duplicate_static(x_train)\n",
        "x_val_concat = remove_duplicate_static(x_val)\n",
        "x_test_concat = remove_duplicate_static(x_test)"
      ],
      "metadata": {
        "id": "3iHld6bVyz_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_concat.shape)\n",
        "print(x_val_concat.shape)\n",
        "print(x_test_concat.shape)"
      ],
      "metadata": {
        "id": "PD14tX63y1Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appendix B and Appendix C discuss a \"ranking\" that model attempts to create. One of the goals of the paper is to select the right patients that should be sent home for care, but this is difficult when some patients may require an \"intervention\". This is where the \"ranking\" comes in. We want to be able to rank patients according to who will **first** require intervention.\n",
        "\n",
        "In order to achieve this, we need to take our input features and do the following:\n",
        "\n",
        "1) Randomly choose pairs of rows from our data and \"group\" them together. Basically, we are creating a 3rd dimension where `data[:, :, 0]` is patient A and `data[:, :, 1]` is patient B.\n",
        "\n",
        "2) We need to create a ranking for every pair of patient in our data (so the model can learn how to do the ranking). This ranking is based on who requires intervention first. In make_3d_tensor_slices, we already calculated for every patient window, how many hours into the future the patient requires intervention. So in \"create_pairs\" we just compare the \"tintv\" (time until intervention) for both patients A and B and create a label based on that."
      ],
      "metadata": {
        "id": "rwQ8WPtlPlO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pairs(X_concat, y_labels, num_pairs=50000):\n",
        "    # Extract tintv\n",
        "    tintv = y_labels[:,1]\n",
        "\n",
        "    num_samples = X_concat.shape[0]\n",
        "\n",
        "    pairs_data = []  # we will store (feature_dim, 2) slices\n",
        "    yrank = []\n",
        "    yintv = []\n",
        "\n",
        "    rng = np.random.default_rng(seed=42)  # reproducible\n",
        "\n",
        "    while len(pairs_data) < num_pairs:\n",
        "        idx1, idx2 = rng.integers(low=0, high=num_samples, size=2)\n",
        "\n",
        "        # Ensure different tintv values\n",
        "        if tintv[idx1] == tintv[idx2]:\n",
        "            continue\n",
        "\n",
        "        x1 = X_concat[idx1]\n",
        "        x2 = X_concat[idx2]\n",
        "\n",
        "        t1 = tintv[idx1]\n",
        "        t2 = tintv[idx2]\n",
        "\n",
        "        # Label: 1 if patient 1 is more urgent (smaller tintv)\n",
        "        label = 1 if t1 < t2 else 0\n",
        "\n",
        "        pair = np.stack([x1, x2], axis=-1)  # (feature_dim, 2)\n",
        "        # print(pair)\n",
        "        pairs_data.append(pair)\n",
        "        yrank.append(label)\n",
        "        yintv.append(np.stack([y_labels[idx1, 0], y_labels[idx2, 0]], axis=-1))\n",
        "    # Convert to numpy arrays\n",
        "    # Stack everything into a big tensor\n",
        "    # print(pairs_data)\n",
        "    pairs_data = np.stack(pairs_data)  # shape: (num_pairs, feature_dim, 2)\n",
        "    yrank = np.array(yrank)\n",
        "    yintv = np.stack(yintv)\n",
        "    return pairs_data, yrank, yintv"
      ],
      "metadata": {
        "id": "W7Qz9JM2BJKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_TRAIN, YRANK_TRAIN, YINTV_TRAIN = create_pairs(x_train_concat, y_train, 100)"
      ],
      "metadata": {
        "id": "KLDgGS3yCNs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_VAL, YRANK_VAL, YINTV_VAL = create_pairs(x_train_concat, y_train, 10)"
      ],
      "metadata": {
        "id": "RBoUurBiCWRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_TEST, YRANK_TEST, YINTV_TEST = create_pairs(x_train_concat, y_train, 10)"
      ],
      "metadata": {
        "id": "Wx8VTzS1F0MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the base multirank model\n",
        "\n",
        "If you receive an error related to the device, try going to \"Runtime > Change Runtime Type\" and pick the T4 option."
      ],
      "metadata": {
        "id": "GZpjndhQTcF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net_type = 'mlp'  # type of NN to use -- currently only affects output filenames\n",
        "opt = 'adam'  # optimizer to use -- allowed are adam and sgd\n",
        "scale_type = 'standard'\n",
        "input_dim = 30  # size of the input to embedding (linear function of input).\n",
        "embed_dim1 = 10  # size of the first hidden embedding layer.\n",
        "embed_dim2 = 10  # size of the second hidden embedding layer.\n",
        "epochs = 50  # number of epochs\n",
        "lr = 1e-5  # learning rate parameter for training\n",
        "bs = 32  # batch size parameter for training\n",
        "loss_wts = [1, 1]  # relative weight of ranking loss [first val] vs prediction loss [second val]\n",
        "# identify the device to run on, preferring cuda and defaulting to cpu\n",
        "device = None\n",
        "for d in ('cuda:1', 'cuda:0', \"cpu\"):\n",
        "    try:\n",
        "        device = torch.device(d)\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "feat_dim = X.shape[1]"
      ],
      "metadata": {
        "id": "YWTUMHFz6Nl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "0c83cac6-42f9-486f-c909-c2788d6ba9de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6f28b3d0db91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mfeat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from CFVAE.model import MultiTaskMLPModel\n",
        "from CFVAE.utils import train_multitask, evaluate_multitask\n",
        "\n",
        "model = MultiTaskMLPModel(feat_dim=feat_dim, inp_emb=input_dim, emb_dim1=embed_dim1, emb_dim2=embed_dim2)\n",
        "model_name = f'multitaskmlp_{input_dim}embed_{embed_dim1}fc1_{embed_dim2}fc2_{epochs}epochs_{bs}bs_{lr}lr'"
      ],
      "metadata": {
        "id": "8_aCJHkY92Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "lMTWVyTH97Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "opt_fn = {'adam': optim.Adam, 'sgd': optim.SGD}[opt.lower()]\n",
        "optimizer = opt_fn(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "w07-AEi9-SiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "num_0 = len(np.where(y_train[:, 0] == 0))\n",
        "num_1 = len(np.where(y_train[:, 0] == 1)[0])\n",
        "\n",
        "num = max(num_0, num_1)\n",
        "\n",
        "wt = [num / num_0, num / num_1]\n",
        "wt = torch.FloatTensor(wt)"
      ],
      "metadata": {
        "id": "vOymJwBC-XT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "criterion_pred = nn.CrossEntropyLoss(weight=wt)\n",
        "criterion_rank = nn.BCELoss()\n",
        "# writer = SummaryWriter(paths['logs'] + model_name)\n",
        "best_val_loss = float(\"inf\")"
      ],
      "metadata": {
        "id": "hZ1vaXBS_E00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from CFVAE.utils import train_multitask, evaluate_multitask\n",
        "import time\n",
        "\n",
        "epochs = 50 # just for testing\n",
        "for epoch in range(1, epochs + 1):\n",
        "  epoch_start_time = time.time()\n",
        "  total_rank_loss, total_pred_loss = train_multitask(device, model, optimizer, loss_wts, criterion_rank,\n",
        "                                                       criterion_pred, bs, lr, epoch, epochs, X_TRAIN,\n",
        "                                                       YRANK_TRAIN, YINTV_TRAIN)\n",
        "\n",
        "  val_loss_rank, val_loss_pred, acc_intv, auc_intv, _, acc_rank, auc_rank, _ = evaluate_multitask(device, model,\n",
        "                                                                                                    optimizer, loss_wts,\n",
        "                                                                                                    criterion_rank,\n",
        "                                                                                                    criterion_pred, bs,\n",
        "                                                                                                    lr, epoch, epochs,\n",
        "                                                                                                    X_VAL,\n",
        "                                                                                                    YRANK_VAL,\n",
        "                                                                                                    YINTV_VAL)\n",
        "\n",
        "  print('-' * 95)\n",
        "  print(\n",
        "      '|end of epoch {:3d}| time: {:5.2f}s| valid rank loss {:5.2f} | valid pred loss {:5.2f} | valid rank auc {:5.2f} | valid pred auc {:5.2f} |'.format(\n",
        "          epoch, (time.time() - epoch_start_time), val_loss_rank, val_loss_pred, auc_rank, auc_intv))\n",
        "  print('-' * 95)\n",
        "\n",
        "  if ((loss_wts[0] * val_loss_rank + loss_wts[1] * val_loss_pred) < best_val_loss):\n",
        "        best_val_loss = loss_wts[0] * val_loss_rank + loss_wts[1] * val_loss_pred\n",
        "        best_model = model"
      ],
      "metadata": {
        "id": "_Ej3d81L_PSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_rank, test_loss_pred, test_acc_intv, test_auc_intv, test_conf_intv, test_acc_rank, test_auc_rank, test_conf_rank = evaluate_multitask(\n",
        "    device, model, optimizer, loss_wts, criterion_rank, criterion_pred, bs, lr, epoch, epochs, X_TEST,\n",
        "    YRANK_TEST, YINTV_TEST)\n",
        "\n",
        "val_loss_rank, val_loss_pred, val_acc_intv, val_auc_intv, val_conf_intv, val_acc_rank, val_auc_rank, val_conf_rank = evaluate_multitask(\n",
        "    device, best_model, optimizer, loss_wts, criterion_rank, criterion_pred, bs, lr, epoch, epochs, X_VAL,\n",
        "    YRANK_VAL, YINTV_VAL)"
      ],
      "metadata": {
        "id": "4UnAVr-D_TYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('=' * 95)\n",
        "print(\n",
        "    '|end of training {:3d}| time: {:5.2f}s| test rank loss {:5.2f} | test pred loss {:5.2f} | test rank auc {:5.2f} | test pred auc {:5.2f} |'.format(\n",
        "        epoch, (time.time() - epoch_start_time), test_loss_rank, test_loss_pred, test_auc_intv, test_auc_rank))"
      ],
      "metadata": {
        "id": "KTcFMMk9Dy5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produce counterfactuals for the multirank model"
      ],
      "metadata": {
        "id": "fhUbLkIDTXVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_counterfactuals(model, x_real, target_label, num_attempts=10):\n",
        "\n",
        "    model.eval()\n",
        "    device = x_real.device\n",
        "    bs = x_real.size(0)\n",
        "\n",
        "    cf_examples = torch.zeros_like(x_real, device=device)\n",
        "    success_mask = torch.zeros(bs, dtype=torch.bool, device=device)\n",
        "\n",
        "    # get posterior params for the whole batch\n",
        "    z_mean, z_logvar = model.encoder(x_real)           # each is (bs, z_dim)\n",
        "    std = torch.exp(0.5 * z_logvar)\n",
        "\n",
        "    for i in range(bs):\n",
        "        # slice out this sample’s mean/std\n",
        "        mu_i  = z_mean[i : i+1]\n",
        "        std_i = std[i : i+1]\n",
        "\n",
        "        for _ in range(num_attempts):\n",
        "            # sample latent → decode → classify\n",
        "            z_i = mu_i + std_i * torch.randn_like(std_i)\n",
        "            x_cf = model.decoder(z_i)                  # (1, feat_dim)\n",
        "            pred = model.classifier(x_cf).argmax(dim=1).item()\n",
        "\n",
        "            if pred == target_label:\n",
        "                cf_examples[i]  = x_cf\n",
        "                success_mask[i] = True\n",
        "                break\n",
        "        else:\n",
        "            # if we never broke out, just save the last sample\n",
        "            cf_examples[i] = x_cf\n",
        "\n",
        "    return cf_examples, success_mask\n",
        "\n"
      ],
      "metadata": {
        "id": "QTz5hxHdTsHG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AA: generating cfs from the test batch\n",
        "\n",
        "x_batch = torch.from_numpy(X_TEST[:32]).to(device)\n",
        "cf_samples, flipped = generate_counterfactuals(best_model, x_batch, target_label=1, num_attempts=20)\n",
        "\n",
        "print(f\"{flipped.sum().item()}/{len(flipped)} examples flipped successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "BrNgV0Fjah4g",
        "outputId": "cc28ea32-4e76-41c8-bd0d-168881512f5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_TEST' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-18b87c37a97d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AA: generating cfs from the test batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_TEST\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcf_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_counterfactuals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_attempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_TEST' is not defined"
          ]
        }
      ]
    }
  ]
}